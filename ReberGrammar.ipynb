{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0284893-d169-4f1b-8742-01ff6108e228",
   "metadata": {},
   "source": [
    "# Long Short Term Memory On Reber Grammar\n",
    "\n",
    "This notebook is using a long-short term memory architecture to solve Reber Grammar, and to see whether a LSTM system can train to generate a string that follows the rule, specifically the rule that requires the 2nd and 2nd to last characters to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801306bb-ca39-4798-ae1a-5e66600d8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636c486-ebc9-4c4f-8887-20eed7d80b70",
   "metadata": {},
   "source": [
    "Here, the graphs and one-hot-encoding structures are hard-defined to be used later. The graph, pictured below, is implemented with the Graph structure. The nodepositions are the paths, and the pairings/inverse pairings are lookup dictionaries. "
   ]
  },
  {
   "attachments": {
    "94006857-c46c-45fc-a175-a5bc427104ab.gif": {
     "image/gif": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a103077c-a8b6-4d60-ad32-f2bfb7adb4f9",
   "metadata": {},
   "source": [
    "![embreber.gif](attachment:94006857-c46c-45fc-a175-a5bc427104ab.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc35eaa8-d44c-4b0c-a425-ffb5b58a1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    1: [2],\n",
    "    2: [3, 4],\n",
    "    3: [3, 6],\n",
    "    4: [4, 5],\n",
    "    5: [3, 7],\n",
    "    6: [7],\n",
    "    7: [8]\n",
    "}\n",
    "\n",
    "node_positions= {\n",
    "    (1, 2) :'B',\n",
    "    (2, 3):'P',\n",
    "    (3, 3): 'T',\n",
    "    (3, 6): 'V',\n",
    "    (2, 4): 'T',\n",
    "    (4, 4): 'S',\n",
    "    (4, 5): 'X',\n",
    "    (5, 3): 'X',\n",
    "    (6, 5): 'P',\n",
    "    (5, 7):'S',\n",
    "    (6, 7): 'V',\n",
    "    (7, 8): 'E'\n",
    "}\n",
    "\n",
    "valid_starts = ['T', 'P']\n",
    "\n",
    "pairings = {\n",
    "    'B':(1,0,0,0,0,0,0),\n",
    "    'T':(0,1,0,0,0,0,0),\n",
    "    'P':(0,0,1,0,0,0,0),\n",
    "    'S':(0,0,0,1,0,0,0),\n",
    "    'X':(0,0,0,0,1,0,0),\n",
    "    'V':(0,0,0,0,0,1,0),\n",
    "    'E':(0,0,0,0,0,0,1)\n",
    "}\n",
    "\n",
    "inverse_pairings = {\n",
    "    (1,0,0,0,0,0,0):'B',\n",
    "    (0,1,0,0,0,0,0):'T',\n",
    "    (0,0,1,0,0,0,0):'P',\n",
    "    (0,0,0,1,0,0,0):'S',\n",
    "    (0,0,0,0,1,0,0):'X',\n",
    "    (0,0,0,0,0,1,0):'V',\n",
    "    (0,0,0,0,0,0,1):'E'\n",
    "}\n",
    "\n",
    "disallowed_pairings = {\n",
    "    'B': ('B', 'S', 'X', 'V', 'E'),\n",
    "    'T': ('B', 'P', 'X', 'E'),\n",
    "    'P': ('B', 'P', 'V', 'E'),\n",
    "    'S': ('B', 'T', 'P', 'V'),\n",
    "    'X': ('B', 'P', 'V', 'E'),\n",
    "    'V': ('B', 'T', 'S', 'X'),\n",
    "    'E':('B', 'T', 'P', 'S', 'X', 'V', 'E')\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e732ac-3e98-4171-9ed0-be0bcc766185",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    1: [2],\n",
    "    2: [3, 4],\n",
    "    3: [3, 6],\n",
    "    4: [4, 5],\n",
    "    5: [3, 7],\n",
    "    6: [7],\n",
    "    7: [8]\n",
    "}\n",
    "\n",
    "node_positions= {\n",
    "    (1, 2) :'B',\n",
    "    (2, 3):'P',\n",
    "    (3, 3): 'T',\n",
    "    (3, 6): 'V',\n",
    "    (2, 4): 'T',\n",
    "    (4, 4): 'S',\n",
    "    (4, 5): 'X',\n",
    "    (5, 3): 'X',\n",
    "    (6, 5): 'P',\n",
    "    (5, 7):'S',\n",
    "    (6, 7): 'V',\n",
    "    (7, 8): 'E'\n",
    "}\n",
    "\n",
    "valid_starts = ['T', 'P']\n",
    "\n",
    "pairings = {\n",
    "    'B':(1,0,0,0,0,0,0),\n",
    "    'T':(0,1,0,0,0,0,0),\n",
    "    'P':(0,0,1,0,0,0,0),\n",
    "    'S':(0,0,0,1,0,0,0),\n",
    "    'X':(0,0,0,0,1,0,0),\n",
    "    'V':(0,0,0,0,0,1,0),\n",
    "    'E':(0,0,0,0,0,0,1)\n",
    "}\n",
    "\n",
    "inverse_pairings = {\n",
    "    (1,0,0,0,0,0,0):'B',\n",
    "    (0,1,0,0,0,0,0):'T',\n",
    "    (0,0,1,0,0,0,0):'P',\n",
    "    (0,0,0,1,0,0,0):'S',\n",
    "    (0,0,0,0,1,0,0):'X',\n",
    "    (0,0,0,0,0,1,0):'V',\n",
    "    (0,0,0,0,0,0,1):'E'\n",
    "}\n",
    "\n",
    "disallowed_pairings = {\n",
    "    'B': ('B', 'S', 'X', 'V', 'E'),\n",
    "    'T': ('B', 'P', 'X', 'E'),\n",
    "    'P': ('B', 'P', 'V', 'E'),\n",
    "    'S': ('B', 'T', 'P', 'V'),\n",
    "    'X': ('B', 'P', 'V', 'E'),\n",
    "    'V': ('B', 'T', 'S', 'X'),\n",
    "    'E':('B', 'T', 'P', 'S', 'X', 'V', 'E')\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727a54a-cb94-4394-9697-befd390b694f",
   "metadata": {},
   "source": [
    "## Reber Generator Class\n",
    "\n",
    "To train and test the model, we must feed it valid Reber grammar strings, which are built in the ReberGenerator class. The walk starts at node 1, which is right before the path of B, and initializes an empty path. It then loops while the current node is not the last one, where it gets the nearby nodes and picks one at random to go to, then appending the letter that corresponds to the path taken between the current and next node. This repeats until the end of the path. The string must always start with a B, then with a T|P, and ends with a T|P B, which are hardcoded into the generating random strings.\n",
    "\n",
    "## Reasons for not generating false examples\n",
    "\n",
    "The idea behind this is to generate a string. False examples might make it slightly better, however it needs to learn the rules of the grammar which it can only do with positive examples. If it learns whats allowed it will only generate things that are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8451cf9-64ef-4bf9-a51f-2864d82723b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReberGenerator:\n",
    "    def __init__(self, graph, node_positions, pairings, valid_starts, inverse_pairings, disallowed_pairings):\n",
    "        self.graph = graph\n",
    "        self.node_positions = node_positions\n",
    "        self.pairings = pairings\n",
    "        self.valid_starts = valid_starts\n",
    "        self.inverse_pairings = inverse_pairings\n",
    "        self.disallowed_pairings = disallowed_pairings\n",
    "\n",
    "    def walk(self):\n",
    "        current_node = 1\n",
    "        path = []\n",
    "        while current_node != 8:\n",
    "            neighbors = self.graph.get(current_node)\n",
    "            next_node = random.choice(neighbors)\n",
    "            path.append(self.node_positions[(current_node, next_node)])\n",
    "            current_node = next_node\n",
    "        return path\n",
    "\n",
    "    def generate_valid_strings(self):\n",
    "        start_end = random.randint(0, 1)\n",
    "        string = ['B']\n",
    "        string.append(self.valid_starts[start_end])\n",
    "        path = self.walk()\n",
    "        path.append(self.valid_starts[start_end])\n",
    "        path.append('E')\n",
    "        return string + path\n",
    "\n",
    "reber_gen = ReberGenerator(graph, node_positions, pairings, valid_starts, inverse_pairings, disallowed_pairings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1374c8-c462-4462-9010-07e2c6b8cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(reber_gen, train_size=1000, test_size=500):\n",
    "    print(f\"Generating training set with {train_size} entries\")\n",
    "    train_strings = []\n",
    "    for _ in range(train_size):\n",
    "        train_strings.append(reber_gen.generate_valid_strings())\n",
    "\n",
    "    \n",
    "    print(f\"Generating testing strings with {test_size} entries\")\n",
    "    test_strings = []\n",
    "    train_set = set([tuple(s) for s in train_strings])\n",
    "    print(f\"Ensuring no overlap\")\n",
    "\n",
    "    #attempts = 0\n",
    "    while len(test_strings) < test_size:\n",
    "        test_candidate = reber_gen.generate_valid_strings()\n",
    "        if tuple(test_candidate) not in train_set:\n",
    "            test_strings.append(test_candidate)\n",
    "        #attemps+=1\n",
    "\n",
    "    print(f\"Generated {len(train_strings)} training, {len(test_strings)} test strings\")\n",
    "    return train_strings, test_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437cbd4e-210e-454f-bc13-84c2137b3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_examples(strings, pairings):\n",
    "    examples = []\n",
    "    for string in strings:\n",
    "        for i in range(len(string) - 1):\n",
    "            input_chars = [pairings[c] for c in string[:i+1]]\n",
    "            target_char = string[i+1]\n",
    "            examples.append((input_chars, pairings[target_char]))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f3d53b-4f62-460e-9f78-759ef14f8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(7, hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 7)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-0.2, 0.2)\n",
    "\n",
    "    def forward(self ,x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b3e38d-6711-4178-95ab-6dc001241de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perfect_prediction(model, examples):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_seq, target_vec in examples:\n",
    "            input_tensor = torch.tensor([list(char) for char in input_seq], dtype=torch.float32).unsqueeze(0)\n",
    "            target_index = torch.argmax(torch.tensor(target_vec, dtype=torch.float32))\n",
    "            \n",
    "            output = model(input_tensor)\n",
    "            predicted = torch.argmax(output)\n",
    "            \n",
    "            if predicted == target_index:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    return correct == total, correct / total  # (Perfect success, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d65497c-337d-40f5-9563-5dd062c60e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_paper_protocol(model, train_examples, test_examples, lr=0.1, max_epochs=1000):\n",
    "    \"\"\"Train following exact paper protocol\"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)  # Paper used SGD\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Randomly sample from training set\n",
    "        random.shuffle(train_examples)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for input_seq, target_vec in train_examples:\n",
    "            # Convert to tensors\n",
    "            input_tensor = torch.tensor([list(char) for char in input_seq], dtype=torch.float32).unsqueeze(0)\n",
    "            target_index = torch.argmax(torch.tensor(target_vec, dtype=torch.float32)).unsqueeze(0)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_tensor)\n",
    "            loss = criterion(output, target_index)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Test every 50 epochs\n",
    "        if epoch % 200 == 0:\n",
    "            train_perfect, train_acc = test_perfect_prediction(model, train_examples[:150])\n",
    "            test_perfect, test_acc = test_perfect_prediction(model, test_examples[:50])\n",
    "            \n",
    "            print(f\"Epoch {epoch}: Loss={total_loss/len(train_examples):.4f}, \"\n",
    "                  f\"Train={train_acc:.3f}, Test={test_acc:.3f}, \"\n",
    "                  f\"Perfect: Train={train_perfect}, Test={test_perfect}\")\n",
    "            \n",
    "            # Success criteria: perfect prediction on both sets\n",
    "            if train_perfect and test_perfect:\n",
    "                print(f\"PERFECT PREDICTION ACHIEVED at epoch {epoch}!\")\n",
    "                return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4031c8a-1979-46d0-8257-8d6e013c1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(reber_gen):\n",
    "    # Generate datasets\n",
    "    train_strings, test_strings = generate_datasets(reber_gen, train_size=500, test_size=200)\n",
    "    train_examples = create_training_examples(train_strings, reber_gen.pairings)\n",
    "    test_examples = create_training_examples(test_strings, reber_gen.pairings)\n",
    "    \n",
    "    print(f\"Training examples: {len(train_examples)}\")\n",
    "    print(f\"Test examples: {len(test_examples)}\")\n",
    "    \n",
    "    # Test LSTM architectures from paper\n",
    "    architectures = [\n",
    "        (\"4 blocks of size 1\", 4),\n",
    "        (\"3 blocks of size 2\", 6)\n",
    "    ]\n",
    "    \n",
    "    for name, hidden_size in architectures:\n",
    "        print(f\"\\n=== Testing {name} (hidden_size={hidden_size}) ===\")\n",
    "        model = LSTM(hidden_size=hidden_size)\n",
    "        success = train_paper_protocol(model, train_examples, test_examples, lr=0.1)\n",
    "        if success:\n",
    "            print(f\"{name} achieved perfect prediction!\")\n",
    "        else:\n",
    "            print(f\"{name} failed to achieve perfect prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dcbdf4-4b21-42e5-afee-57a210cb6110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training set with 500 entries\n",
      "Generating testing strings with 200 entries\n",
      "Ensuring no overlap\n",
      "Generated 500 training, 200 test strings\n",
      "Training examples: 4852\n",
      "Test examples: 3008\n",
      "\n",
      "=== Testing 4 blocks of size 1 (hidden_size=4) ===\n",
      "Epoch 0: Loss=0.9581, Train=0.687, Test=0.500, Perfect: Train=False, Test=False\n",
      "Epoch 200: Loss=0.3712, Train=0.767, Test=0.660, Perfect: Train=False, Test=False\n",
      "Epoch 400: Loss=0.3643, Train=0.820, Test=0.740, Perfect: Train=False, Test=False\n",
      "Epoch 600: Loss=0.3654, Train=0.720, Test=0.660, Perfect: Train=False, Test=False\n"
     ]
    }
   ],
   "source": [
    "run_experiment(reber_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
